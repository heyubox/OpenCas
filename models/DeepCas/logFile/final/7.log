===================configuration===================
dropout prob: 1.0
l2 1e-08
learning rate: 0.0005
emb_learning_rate: 0.005
observation hour [7,19]
observation threshold: 7
prediction time: 86400
cascade length [10,100]
model save at../model_save/deepcas/dblp2/
===================configuration===================
56612 12131 12132
(?, 200, 10, 50)
<class 'int'> <class 'int'>
Total_parameters:28420770
#1, Training Loss= 8.813354, Validation Loss= 2.762439, Test Loss= 2.717603, Best Valid Loss= 2.762439, Best Test Loss= 2.717603
consuming time in one epoch 104.11861205101013
#2, Training Loss= 1.513498, Validation Loss= 2.150520, Test Loss= 2.089878, Best Valid Loss= 2.150520, Best Test Loss= 2.089878
consuming time in one epoch 102.20060610771179
#3, Training Loss= 0.661297, Validation Loss= 2.109884, Test Loss= 2.039998, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.1734209060669
#4, Training Loss= 0.325044, Validation Loss= 2.159724, Test Loss= 2.089714, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.85463690757751
#5, Training Loss= 0.194560, Validation Loss= 2.173266, Test Loss= 2.119537, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.62395215034485
#6, Training Loss= 0.125825, Validation Loss= 2.198354, Test Loss= 2.142128, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 110.13472747802734
#7, Training Loss= 0.083157, Validation Loss= 2.244648, Test Loss= 2.201634, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 110.48119306564331
#8, Training Loss= 0.060388, Validation Loss= 2.217089, Test Loss= 2.179070, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 108.25152635574341
#9, Training Loss= 0.046428, Validation Loss= 2.155007, Test Loss= 2.110730, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.44106888771057
#10, Training Loss= 0.036781, Validation Loss= 2.153300, Test Loss= 2.106258, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.42603325843811
#11, Training Loss= 0.029230, Validation Loss= 2.136833, Test Loss= 2.107937, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.68150591850281
#12, Training Loss= 0.023884, Validation Loss= 2.138906, Test Loss= 2.096864, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.64143824577332
#13, Training Loss= 0.020256, Validation Loss= 2.143087, Test Loss= 2.116166, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.39397239685059
#14, Training Loss= 0.017646, Validation Loss= 2.171486, Test Loss= 2.134486, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.40635895729065
#15, Training Loss= 0.016153, Validation Loss= 2.167924, Test Loss= 2.133220, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.7129578590393
#16, Training Loss= 0.013820, Validation Loss= 2.150154, Test Loss= 2.111455, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.68630027770996
#17, Training Loss= 0.012412, Validation Loss= 2.180083, Test Loss= 2.148469, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.66311287879944
#18, Training Loss= 0.012147, Validation Loss= 2.153294, Test Loss= 2.122882, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.33705806732178
#19, Training Loss= 0.011413, Validation Loss= 2.175674, Test Loss= 2.144079, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.47943305969238
#20, Training Loss= 0.010390, Validation Loss= 2.184266, Test Loss= 2.147648, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.56655955314636
#21, Training Loss= 0.009817, Validation Loss= 2.191355, Test Loss= 2.157736, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 109.0734486579895
#22, Training Loss= 0.009336, Validation Loss= 2.203929, Test Loss= 2.168705, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 110.97489905357361
#23, Training Loss= 0.008659, Validation Loss= 2.185330, Test Loss= 2.155704, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 110.36549949645996
#24, Training Loss= 0.008046, Validation Loss= 2.200997, Test Loss= 2.166930, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 103.21054291725159
#25, Training Loss= 0.007775, Validation Loss= 2.195156, Test Loss= 2.155371, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.28722500801086
#26, Training Loss= 0.007860, Validation Loss= 2.180744, Test Loss= 2.145371, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 101.66623520851135
#27, Training Loss= 0.007344, Validation Loss= 2.193376, Test Loss= 2.156819, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.527334690094
#28, Training Loss= 0.006826, Validation Loss= 2.198272, Test Loss= 2.175833, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.50352668762207
#29, Training Loss= 0.006599, Validation Loss= 2.215683, Test Loss= 2.182455, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.63160967826843
#30, Training Loss= 0.006200, Validation Loss= 2.207477, Test Loss= 2.169290, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.5523521900177
#31, Training Loss= 0.005942, Validation Loss= 2.201026, Test Loss= 2.162616, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
consuming time in one epoch 102.55408000946045
#32, Training Loss= 0.005776, Validation Loss= 2.207848, Test Loss= 2.168381, Best Valid Loss= 2.109884, Best Test Loss= 2.039998
Finished!
----------------------------------------------------------------
Time: 102.34479546546936
Valid Loss: 2.1098838
Test Loss: 2.039998
