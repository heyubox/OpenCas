===========DeepHawkes loading cascade===========
save valid id in:../data/deephawkes/dblp/
total_readin: 151247
discard_midnight: 0
discard_outer: 86493
total: 64754
train data: 45327
valid data: 9714
test data: 9713
train test valid 45327 9713 9714
total data: 64754
total time in preprocessing: 39.80879211425781
45327 9714 9713
max_size 100
max_size 99
max_size 100
Number of sequence: 100
120.0
max_num: 100
max_num: 99
max_num: 100

 length of sequence: 13
13 13 12
length of original isd: 317377
length of original isd: 130317
length of original isd: 129111
lenth of original_ids: 364394
45327
blank_template 13 [364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392]
data num: 45327 14 13
num remove:0 in dataset
blank_template 13 [364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392]
data num: 9714 13 13
num remove:0 in dataset
blank_template 13 [364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392, 364392]
data num: 9713 13 13
num remove:0 in dataset
(364394, 120.0, 13)
20.86556649208069
os.environ: 0
1.14.0
ok
dataset information: nodes:364394, n_sequence:120, n_steps:13 
===================configuration===================
dropout prob :  0.001
l2 0.05
learning rate :  0.005
emb_learning_rate :  0.005
observation hour [7,19]
observation threshold :  5
prediction time :  86400
cascade length [10,100]
model save at : ../model_save/deephawkes/dblp/
===================configuration===================
---------***---------
Number: 45327, Max: 12.073806847178494 and Min: 0.0 label Value in Train
NUmber: 9713, Max: 11.584962500721158 and Min: 0.0 label Value in Test
NUmber: 9714, Max: 12.354249381945241 and Min: 0.0 label Value in Valid
---------***---------
45327 9713 9714
Total_parameters:18244954
finish one epoch, time202.19895195960999

train mseloss : 1.669084234954069
lambda1 [-0.   -0.01  0.02  0.07  0.12]
#0, Training Loss= 1.66455, Valid Loss= 1.67400, Valid median Loss= 0.74373, Best Valid Loss= 1.67400, Test Loss= 1.66936, Test median  Loss= 0.72191, Best Test Loss= 1.66936
finish one epoch, time697.0608191490173

train mseloss : 1.641598703536895
lambda1 [ 0.   -0.    0.02  0.06  0.11]
#1, Training Loss= 1.64408, Valid Loss= 1.65073, Valid median Loss= 0.73864, Best Valid Loss= 1.65073, Test Loss= 1.64377, Test median  Loss= 0.72132, Best Test Loss= 1.64377
finish one epoch, time1275.8966581821442

train mseloss : 1.5754530514391125
lambda1 [ 0.   -0.    0.03  0.06  0.11]
#2, Training Loss= 1.57547, Valid Loss= 1.57591, Valid median Loss= 0.69244, Best Valid Loss= 1.57591, Test Loss= 1.58082, Test median  Loss= 0.66210, Best Test Loss= 1.58082
finish one epoch, time1863.7348177433014

train mseloss : 1.5704897218126392
lambda1 [ 0.01 -0.01  0.02  0.05  0.11]
#3, Training Loss= 1.57141, Valid Loss= 1.57410, Valid median Loss= 0.69066, Best Valid Loss= 1.57410, Test Loss= 1.58170, Test median  Loss= 0.68355, Best Test Loss= 1.58082
finish one epoch, time2431.4015510082245

train mseloss : 1.6121091602916795
lambda1 [ 0.   -0.01  0.02  0.06  0.11]
#4, Training Loss= 1.61515, Valid Loss= 1.61815, Valid median Loss= 0.71007, Best Valid Loss= 1.57410, Test Loss= 1.62093, Test median  Loss= 0.69908, Best Test Loss= 1.58082
finish one epoch, time3002.768882036209

train mseloss : 1.5736595506928355
lambda1 [0.01 0.   0.02 0.07 0.11]
#5, Training Loss= 1.57472, Valid Loss= 1.58328, Valid median Loss= 0.69004, Best Valid Loss= 1.57410, Test Loss= 1.58598, Test median  Loss= 0.66967, Best Test Loss= 1.58082
finish one epoch, time3531.210356235504

train mseloss : 1.5709486424406804
lambda1 [ 0.01 -0.    0.01  0.05  0.11]
#6, Training Loss= 1.57036, Valid Loss= 1.57227, Valid median Loss= 0.70363, Best Valid Loss= 1.57227, Test Loss= 1.56947, Test median  Loss= 0.65814, Best Test Loss= 1.56947
finish one epoch, time4051.4614934921265

train mseloss : 1.669587034460097
lambda1 [ 0.01 -0.    0.03  0.06  0.12]
#7, Training Loss= 1.66897, Valid Loss= 1.66285, Valid median Loss= 0.73059, Best Valid Loss= 1.57227, Test Loss= 1.67511, Test median  Loss= 0.69678, Best Test Loss= 1.56947
finish one epoch, time4636.540479898453

train mseloss : 1.6642203045290347
lambda1 [ 0.01 -0.01  0.03  0.06  0.11]
#8, Training Loss= 1.66467, Valid Loss= 1.67381, Valid median Loss= 0.75492, Best Valid Loss= 1.57227, Test Loss= 1.67117, Test median  Loss= 0.73101, Best Test Loss= 1.56947
finish one epoch, time5232.929086685181

train mseloss : 1.6067954254596648
lambda1 [ 0.   -0.01  0.02  0.05  0.11]
#9, Training Loss= 1.60681, Valid Loss= 1.61408, Valid median Loss= 0.71305, Best Valid Loss= 1.57227, Test Loss= 1.61645, Test median  Loss= 0.70258, Best Test Loss= 1.56947
finish one epoch, time5819.420570373535

train mseloss : 1.5953679265030767
lambda1 [ 0.   -0.01  0.03  0.06  0.11]
#10, Training Loss= 1.59348, Valid Loss= 1.59783, Valid median Loss= 0.71112, Best Valid Loss= 1.57227, Test Loss= 1.59689, Test median  Loss= 0.69228, Best Test Loss= 1.56947
finish one epoch, time6402.815979719162

train mseloss : 1.5869835179473974
lambda1 [ 0.01 -0.    0.03  0.06  0.11]
#11, Training Loss= 1.58890, Valid Loss= 1.58859, Valid median Loss= 0.71752, Best Valid Loss= 1.57227, Test Loss= 1.59408, Test median  Loss= 0.65931, Best Test Loss= 1.56947
finish one epoch, time6993.191154956818

train mseloss : 1.5772962786742721
lambda1 [ 0.   -0.    0.02  0.06  0.12]
#12, Training Loss= 1.57827, Valid Loss= 1.58249, Valid median Loss= 0.71496, Best Valid Loss= 1.57227, Test Loss= 1.58711, Test median  Loss= 0.68153, Best Test Loss= 1.56947
finish one epoch, time7577.729632139206

train mseloss : 1.5771881731555135
lambda1 [ 0.01 -0.    0.02  0.06  0.12]
#13, Training Loss= 1.57593, Valid Loss= 1.58405, Valid median Loss= 0.70678, Best Valid Loss= 1.57227, Test Loss= 1.59259, Test median  Loss= 0.66714, Best Test Loss= 1.56947
finish one epoch, time8133.214268922806

train mseloss : 1.6195090483466776
lambda1 [ 0.   -0.    0.03  0.07  0.12]
#14, Training Loss= 1.62214, Valid Loss= 1.62124, Valid median Loss= 0.71442, Best Valid Loss= 1.57227, Test Loss= 1.62865, Test median  Loss= 0.68159, Best Test Loss= 1.56947
finish one epoch, time8624.701673984528

train mseloss : 1.5689395088787095
lambda1 [0.01 0.   0.02 0.07 0.12]
#15, Training Loss= 1.57045, Valid Loss= 1.57384, Valid median Loss= 0.68910, Best Valid Loss= 1.57227, Test Loss= 1.57301, Test median  Loss= 0.65681, Best Test Loss= 1.56947
finish one epoch, time9109.960531949997

train mseloss : 1.592244988560472
lambda1 [ 0.   -0.    0.02  0.07  0.11]
#16, Training Loss= 1.59314, Valid Loss= 1.59070, Valid median Loss= 0.71067, Best Valid Loss= 1.57227, Test Loss= 1.59676, Test median  Loss= 0.69550, Best Test Loss= 1.56947
finish one epoch, time9616.680621623993

train mseloss : 1.5828891657051574
lambda1 [ 0.01 -0.    0.03  0.06  0.11]
#17, Training Loss= 1.58356, Valid Loss= 1.57869, Valid median Loss= 0.69879, Best Valid Loss= 1.57227, Test Loss= 1.59108, Test median  Loss= 0.65665, Best Test Loss= 1.56947
finish one epoch, time10123.640569925308

train mseloss : 1.5659386569328395
lambda1 [ 0.   -0.    0.02  0.06  0.11]
#18, Training Loss= 1.56759, Valid Loss= 1.57410, Valid median Loss= 0.69839, Best Valid Loss= 1.57227, Test Loss= 1.57508, Test median  Loss= 0.66883, Best Test Loss= 1.56947
finish one epoch, time10618.208413124084

train mseloss : 1.6015886282661727
lambda1 [0.   0.01 0.03 0.06 0.11]
#19, Training Loss= 1.59766, Valid Loss= 1.59112, Valid median Loss= 0.69453, Best Valid Loss= 1.57227, Test Loss= 1.60252, Test median  Loss= 0.66193, Best Test Loss= 1.56947
finish one epoch, time11111.76942563057

train mseloss : 1.5819274193980537
lambda1 [0.   0.   0.01 0.06 0.11]
#20, Training Loss= 1.58227, Valid Loss= 1.58809, Valid median Loss= 0.70593, Best Valid Loss= 1.57227, Test Loss= 1.59212, Test median  Loss= 0.69157, Best Test Loss= 1.56947
finish one epoch, time11621.14692735672

train mseloss : 1.621931537657356
lambda1 [0.   0.   0.02 0.07 0.12]
#21, Training Loss= 1.62291, Valid Loss= 1.61242, Valid median Loss= 0.71648, Best Valid Loss= 1.57227, Test Loss= 1.63087, Test median  Loss= 0.68805, Best Test Loss= 1.56947
finish one epoch, time12246.325858354568

train mseloss : 1.588821306943923
lambda1 [0.02 0.   0.02 0.07 0.11]
#22, Training Loss= 1.59297, Valid Loss= 1.58887, Valid median Loss= 0.70394, Best Valid Loss= 1.57227, Test Loss= 1.59477, Test median  Loss= 0.66257, Best Test Loss= 1.56947
finish one epoch, time12957.231170892715

train mseloss : 1.5878672828847138
lambda1 [ 0.01 -0.    0.02  0.06  0.11]
#23, Training Loss= 1.58700, Valid Loss= 1.59605, Valid median Loss= 0.72354, Best Valid Loss= 1.57227, Test Loss= 1.59683, Test median  Loss= 0.68808, Best Test Loss= 1.56947
finish one epoch, time13763.351450920105

train mseloss : 1.5691183999620495
lambda1 [0.01 0.   0.03 0.06 0.12]
#24, Training Loss= 1.56751, Valid Loss= 1.56929, Valid median Loss= 0.69367, Best Valid Loss= 1.56929, Test Loss= 1.57007, Test median  Loss= 0.66464, Best Test Loss= 1.56947
finish one epoch, time14634.999294996262

train mseloss : 1.582816443480893
lambda1 [0.02 0.   0.03 0.06 0.12]
#25, Training Loss= 1.58265, Valid Loss= 1.59570, Valid median Loss= 0.71551, Best Valid Loss= 1.56929, Test Loss= 1.58682, Test median  Loss= 0.67579, Best Test Loss= 1.56947
finish one epoch, time15525.402406215668

train mseloss : 1.5660704868930089
lambda1 [0.01 0.   0.02 0.06 0.13]
#26, Training Loss= 1.56560, Valid Loss= 1.56836, Valid median Loss= 0.69366, Best Valid Loss= 1.56836, Test Loss= 1.57460, Test median  Loss= 0.67338, Best Test Loss= 1.56947
finish one epoch, time16253.98151564598

train mseloss : 1.5703686634734881
lambda1 [0.01 0.   0.03 0.06 0.12]
#27, Training Loss= 1.57046, Valid Loss= 1.57130, Valid median Loss= 0.70639, Best Valid Loss= 1.56836, Test Loss= 1.57970, Test median  Loss= 0.65955, Best Test Loss= 1.56947
Finished!
----------------------------------------------------------------
Time: 16689.97619342804
Valid Loss: 1.5683599
Test Loss: 1.5694739
